<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Harshit Joshi - Stanford University PhD Researcher | Publications</title>
<meta name="description" content="CS PhD Student (Graduate Researcher) at Stanford University. Previously, Research Fellow at Microsoft Research. Building Neurosymbolic systems to tame the powers of LLMs and make them usuable in the wild.
">
<meta http-equiv="content-language" content="en">
<meta name="keywords" content="Researcher, Harshit, Harshit Joshi, LLMs, Stanford University, Google Scholar">

<!-- Open Graph -->

<meta property="og:site_name" content="CS PhD Student (Graduate Researcher) at Stanford University. Previously, Research Fellow at Microsoft Research. Building Neurosymbolic systems to tame the powers of LLMs and make them usuable in the wild.
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="Harshit Joshi - Stanford University PhD Researcher" />
<meta property="og:url" content="https://harshitjoshi.com/publications/" />
<meta property="og:description" content="Publications" />
<meta property="og:image"
  content="https://harshitjoshi.com/assets/img/prof_pic.jpg" />
<meta name="thumbnail"
  content="https://harshitjoshi.com/assets/img/prof_pic.jpg" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
  rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css"
  integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"
  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css"
  integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css"
  href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet"
  href="/assets/css/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->




<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JHJ6H2DLJS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-JHJ6H2DLJS');
</script>
  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</head>

<body
  class="fixed-top-nav sticky-bottom-footer">

  <!-- Header -->

  <header>

    <!-- Nav Bar -->
    <div style="display: none;"><h1>Harshit</h1><h2>Harshit</h2></div>

    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://harshitjoshi.com/">
       <span class="font-weight-bold">Harshit</span>   Joshi
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          <!-- CV -->
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/Harshit_Joshi_CV.pdf", target="_blank">
              CV
            </a>
          </li>
          <!-- Resume -->
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/Harshit_Joshi_Resume.pdf", target="_blank">
              Resume
            </a>
          </li>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


  <!-- Content -->

  <div class="container mt-5">
    <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">* denotes equal contribution</p>
  </header>

  <article>
    <div class="publications">



  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge"></abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/worksheets.png" />
    </div>
    
  </div>

  <div id="joshi2024llmbasedopendomainintegratedtask" class="col-sm-7">
    
    <div class="title">LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Liu, Shicheng,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Chen, James,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Weigle, Robert,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Lam, Monica S.
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>arXiv</em>
      
      
      2024
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://arxiv.org/abs/2407.05674" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">2407.05674</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Programming LLM-based knowledge and task assistants that faithfully conform to developer-provided policies is challenging. These agents must retrieve and provide consistent, accurate, and relevant information to address user’s queries and needs. Yet such agents generate unfounded responses ("hallucinate"). Traditional dialogue trees can only handle a limited number of conversation flows, making them inherently brittle. To this end, we present KITA - a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions. Unlike LLMs, KITA provides reliable grounded responses, with controllable agent policies through its expressive specification, KITA Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. Through a real-user study involving 62 participants, we show that KITA beats the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively. We also release 22 real-user conversations with KITA manually corrected to ensure accuracy.</p>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge"></abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/flame_intro.png" />
    </div>
    
  </div>

  <div id="joshi2023flame" class="col-sm-7">
    
    <div class="title">FLAME: A small language model for spreadsheet formulas</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Ebenezer, Abishai,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Cambronero, José,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Gulwani, Sumit,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Kanade, Aditya,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Le, Vu,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Radiček, Ivan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Verbruggen, Gust
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>Proceedings of the AAAI Conference on Artificial Intelligence, 38</em>
      
      
      2024
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://arxiv.org/abs/2301.13779" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">AAAI ’24</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The widespread use of spreadsheet environments by billions of users presents a unique opportunity for formula-authoring assistance. Although large language models, such as Codex, can assist in general-purpose languages, they are expensive to train and challenging to deploy due to their large model sizes (up to billions of parameters). Moreover, they require hundreds of gigabytes of training data. We present FLAME, a T5-based model trained on Excel formulas that leverages domain insights to achieve competitive performance with a substantially smaller model (60M parameters) and two orders of magnitude less training data. We curate a training dataset using sketch deduplication, introduce an Excel-specific formula tokenizer for our model, and use domain-specific versions of masked span prediction and noisy auto-encoding as pretraining objectives. We evaluate FLAME on formula repair, formula auto-completion, and a novel task called syntax reconstruction. FLAME (60M) can outperform much larger models, such as Codex-Davinci (175B), Codex-Cushman (12B), and CodeT5 (220M), in 6 out of 10 settings.</p>
    </div>
    
  </div>
</div></li></ol>


  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge"></abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/ring.png" />
    </div>
    
  </div>

  <div id="joshi-etal-2022-ring" class="col-sm-7">
    
    <div class="title">Repair Is Nearly Generation: Multilingual Program Repair with LLMs</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Cambronero, José,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Gulwani, Sumit,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Le, Vu,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Radicek, Ivan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Verbruggen, Gust
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>Proceedings of the AAAI Conference on Artificial Intelligence, 37</em>
      
      
      2023
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://arxiv.org/abs/2208.11640" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">AAAI ’23</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Most programmers make mistakes when writing code. Some of these mistakes are small and require few edits to the original program - a class of errors recently termed last mile mistakes. These errors break the flow for experienced developers and can stump novice programmers. Existing automated repair techniques targeting this class of errors are domain-specific and do not easily carry over to new domains. Transferring symbolic approaches requires substantial engineering and neural approaches require data and retraining. We introduce RING, a multilingual repair engine powered by a large language model trained on code (LLMC) such as Codex. Such a multilingual engine enables a flipped model for programming assistance, one where the programmer writes code and the AI assistance suggests fixes, compared to traditional code suggestion technology. Taking inspiration from the way programmers manually fix bugs, we show that a prompt-based strategy that conceptualizes repair as localization, transformation, and candidate ranking, can successfully repair programs in multiple domains with minimal effort. We present the first results for such a multilingual repair engine by evaluating on 6 different domains and comparing performance to domain-specific repair engines. We show that RING can outperform domain-specific repair engines in 3 of these domains. We also identify directions for future research using LLMCs for multilingual repair.</p>
    </div>
    
  </div>
</div></li></ol>


  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">OOPSLA 2022</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/oopsla22.png" />
    </div>
    
  </div>

  <div id="bhavishi-etal-2022-neurosymoblic" class="col-sm-7">
    
    <div class="title">Neurosymbolic Repair for Low-Code Formula Languages</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Bavishi, Rohan*,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit*</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Sánchez, José Pablo Cambronero,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Fariha, Anna,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Gulwani, Sumit,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Le, Vu,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Radicek, Ivan,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Tiwari, Ashish
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of the ACM on Programming Languages (OOPSLA2)</em>
      
      
      2022
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://arxiv.org/abs/2207.11765" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">OOPSLA ’22</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Most users of low-code platforms, such as Excel and PowerApps, write programs in domain-specific formula languages to carry out nontrivial tasks. Often users can write most of the program they want, but introduce small mistakes that yield broken formulas. These mistakes, which can be both syntactic and semantic, are hard for low-code users to identify and fix, even though they can be resolved with just a few edits. We formalize the problem of producing such edits as the last-mile repair problem. To address this problem, we developed LaMirage, a LAst-MIle RepAir-engine GEnerator that combines symbolic and neural techniques to perform last-mile repair in low-code formula languages. LaMirage takes a grammar and a set of domain-specific constraints/rules, which jointly approximate the target language, and uses these to generate a repair engine that can fix formulas in that language. To tackle the challenges of localizing the errors and ranking the candidate repairs, LaMirage leverages neural techniques, whereas it relies on symbolic methods to generate candidate repairs. This combination allows LaMirage to find repairs that satisfy the provided grammar and constraints, and then pick the most natural repair. We compare LaMirage to state-of-the-art neural and symbolic approaches on 400 real Excel and PowerFx formulas, where LaMirage outperforms all baselines. We release these benchmarks to encourage subsequent work in low-code domains.</p>
    </div>
    
  </div>
</div></li></ol>


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">ICWSM 21</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/icwsm.png" />
    </div>
    
  </div>

  <div id="sawhney-etal-2021-moderation" class="col-sm-7">
    
    <div class="title">Tweets Classification to Assist Human Moderation for Suicide Prevention</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit*</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit*,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Nobles, Alicia*,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Shah, Rajiv Ratn
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of the International AAAI Conference on Web and Social Media</em>
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/18088" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">ICWSM ’21</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Social media platforms are already engaged in leveraging existing online socio-technical systems to employ just-in-time interventions for suicide prevention to the public. These efforts primarily rely on self-reports of potential self-harm content that is reviewed by moderators. Most recently, platforms have employed automated models to identify self-harm content, but acknowledge that these automated models still struggle to understand the nuance of human language (e.g., sarcasm). By explicitly focusing on Twitter posts that could easily be misidentified by a model as expressing suicidal intent (i.e., they contain similar phrases such as “wanting to die”), our work examines the temporal differences in historical expressions of general and emotional language prior to a clear expression of suicidal intent. Additionally, we analyze time-aware neural models that build on these language variants and factors in the historical, emotional spectrum of a user’s tweeting activity. The strongest model achieves high (statistically significant) performance (macro F1=0.804, recall=0.813) to identify social media indicative of suicidal intent. Using three use cases of tweets with phrases common to suicidal intent, we qualitatively analyze and interpret how such models decided if suicidal intent was present and discuss how these analyses may be used to alleviate the burden on human moderators within the known constraints of how moderation is performed (e.g., no access to the user’s timeline). Finally, we discuss the ethical implications of such data-driven models and inferences about suicidal intent from social media. Content warning: this article discusses self-harm and suicide.</p>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">EACL 21</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/naacl.jpeg" />
    </div>
    
  </div>

  <div id="sawhney-etal-2021-hypersos" class="col-sm-7">
    
    <div class="title">Suicide Ideation Detection via Social and Temporal User Representations using Hyperbolic Learning</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit*</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit*,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Shah, Rajiv Ratn,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Flek, Lucie
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://www.aclweb.org/anthology/2021.naacl-main.176/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      <a href="https://github.com/caisa-lab/hyper-sos-naacl" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">NAACL-HLT ’21</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent psychological studies indicate that individuals exhibiting suicidal ideation increasingly turn to social media rather than mental health practitioners. Personally contextualizing the buildup of such ideation is critical for accurate identification of users at risk. In this work, we propose a framework jointly leveraging a user’s emotional history and social information from a user’s neighborhood in a network to contextualize the interpretation of the latest tweet of a user on Twitter. Reflecting upon the scale-free nature of social network relationships, we propose the use of Hyperbolic Graph Convolution Networks, in combination with the Hawkes process to learn the historical emotional spectrum of a user in a time-sensitive manner. Our system significantly outperforms state-of-the-art methods on this task, showing the benefits of both socially and personally contextualized representations.</p>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge"></abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/jamia_loss.png" />
    </div>
    
  </div>

  <div id="sawhney-2021-jamia" class="col-sm-7">
    
    <div class="title">Robust Suicide Risk Assessment on Social Media via Deep Adversarial Learning</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Gandhi, Saumya,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Jin, Di,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Shah, Rajiv Ratn
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>Journal of the American Medical Informatics Association</em>
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://pubmed.ncbi.nlm.nih.gov/33779728/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">JAMIA ’21</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The prevalence of social media for sharing personal thoughts makes it a viable platform for the assessment of suicide risk. However, deep learning models are not able to capture the diverse nature of linguistic choices and temporal patterns that can be exhibited by a suicidal user on social media and end up overfitting on specific cues that are not generally applicable. We propose Adversarial Suicide assessment Hierarchical Attention (ASHA), a hierarchical attention model that employs adversarial learning for improving the generalization ability of the model.We assess the suicide risk of a social media user across 5 levels of increasing severity of risk. ASHA leverages a transformer-based architecture to learn the semantic nature of social media posts and a temporal attention-based long short-term memory architecture for the sequential modeling of a user’s historical posts. We dynamically generate adversarial examples by adding perturbations to actual examples that can simulate the stochasticity in historical posts, thereby making the model robust.Through extensive experiments, we establish the face-value of ASHA and show that it significantly outperforms existing baselines, with the F1 score of 64%. This is a 2% and a 4% increase over the ContextBERT and ContextCNN baselines, respectively. Finally, we discuss the practical applicability and ethical aspects of our work pertaining to ASHA, as a human-in-the-loop framework.Adversarial samples can be helpful in capturing the diverse nature of suicidal ideation. Through ASHA, we hope to form a component in a larger human-in-the-loop infrastructure for suicide risk assessment on social media.</p>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">EACL 21</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/eacl21.png" />
    </div>
    
  </div>

  <div id="sawhney-etal-2021-phase" class="col-sm-7">
    
    <div class="title">PHASE: Learning Emotional Phase-aware Representations for Suicide Ideation Detection on Social Media</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit*</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit*,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Flek, Lucie,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Shah, Rajiv Ratn
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of 16th Conference of the European Chapter of the Association for Computational Linguistics</em>
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://www.aclweb.org/anthology/2021.eacl-main.205" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      <a href="https://github.com/midas-research/phase-eacl" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">EACL ’21</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent psychological studies indicate that individuals exhibiting suicidal ideation increasingly turn to social media rather than mental health practitioners. Contextualizing the buildup of such ideation is critical for the identification of users at risk. In this work, we focus on identifying suicidal intent in tweets by augmenting linguistic models with emotional phases modeled from users’ historical context.We propose PHASE, a time-and phase-aware framework that adaptively learns features from a user’s historical emotional spectrum on Twitter for preliminary screening of suicidal risk. Building on clinical studies, PHASE learns phase-like progressions in users’ historical Plutchik-wheel-based emotions to contextualize suicidal intent. While outperforming state-of-the-art methods, we show the utility of temporal and phase-based emotional contextual cues for suicide ideation detection. We further discuss practical and ethical considerations.</p>
    </div>
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">WSDM 21</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/wsdm.png" />
    </div>
    
  </div>

  <div id="sawhney2021ordinal" class="col-sm-7">
    
    <div class="title">Towards Ordinal Suicide Ideation Detection on Social Media</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Gandhi, Saumya,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Shah, Rajiv Ratn
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of 14th ACM International Conference On Web Search And Data Mining</em>
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://dl.acm.org/doi/10.1145/3437963.3441805" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      
      
      <a href="https://github.com/midas-research/sismo-wsdm" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">WSDM ’21</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The rising ubiquity of social media presents a platform for individuals to express suicide ideation, instead of traditional, formal clinical settings. While neural methods for assessing suicide risk on social media have shown promise, a crippling limitation of existing solutions is that they ignore the inherent ordinal nature across fine-grain levels of suicide risk. To this end, we reformulate suicide risk assessment as an Ordinal Regression problem, over the Columbia-Suicide Severity Scale. We propose SISMO, a hierarchical attention model optimized to factor in the graded nature of increasing suicide risk levels, through soft probability distribution since not all wrong risk-levels are equally wrong. We establish the face value of SISMO for preliminary suicide risk assessment on real-world Reddit data annotated by clinical experts. We conclude by discussing the empirical, practical, and ethical considerations pertaining to SISMO ina larger picture, as a human-in-the-loop framework.</p>
    </div>
    
  </div>
</div></li></ol>


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
    
    <!-- 
    <abbr class="badge">EMNLP 21</abbr>
     -->
    <div class="float-left">
      <img class="img-fluid" src="/assets/img/emnlp20.jpg" />
    </div>
    
  </div>

  <div id="sawhney-etal-2020-time" class="col-sm-7">
    
    <div class="title">A Time-Aware Transformer Based Model for Suicide Ideation Detection on Social Media</div>
    <div class="author">
      
      
      
      
      

      
      
      
      
      Sawhney, Ramit,
      
      
      
      
      
      
      
      
      

      
      
      
      <em>Joshi, Harshit</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Gandhi, Saumya,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Shah, Rajiv Ratn
      
      
      
      
      
    </div>

    <div class="periodical">
      
      <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>
      
      
      2020
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      <a href="https://www.aclweb.org/anthology/2020.emnlp-main.619" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
      
      
      
      <a href="/assets/pdf/2020.emnlp-main.619.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
      
      
      
      
      <a href="https://github.com/midas-research/STATENet_Time_Aware_Suicide_Assessment" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
      
      
      
      <a href="https://drive.google.com/file/d/1qfW-CYjmYoVa7IUBXPVsNxRFAI-5OIHQ/view" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
      
      
      
      <a href="https://slideslive.com/38939133/a-timeaware-transformer-based-model-for-suicide-ideation-detection-on-social-media" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
      
      
      
      <a class="conference btn-sm z-depth-0" role="button">EMNLP ’20</a>
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Social media’s ubiquity fosters a space for users to exhibit suicidal thoughts outside of traditional clinical settings. Understanding the build-up of such ideation is critical for the identification of at-risk users and suicide prevention. Suicide ideation is often linked to a history of mental depression. The emotional spectrum of a user’s historical activity on social media can be indicative of their mental state over time. In this work, we focus on identifying suicidal intent in English tweets by augmenting linguistic models with historical context. We propose STATENet, a time-aware transformer based model for preliminary screening of suicidal risk on social media. STATENet outperforms competitive methods, demonstrating the utility of emotional and temporal contextual cues for suicide risk assessment. We discuss the empirical, qualitative, practical, and ethical aspects of STATENet for suicide ideation detection.</p>
    </div>
    
  </div>
</div></li></ol>


</div>

  </article>

</div>

  </div>

  <!-- Footer -->

  
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2024 Harshit  Joshi.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



</body>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>





<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>